{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7fdb453a0160>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This notebook was adapted from kgero's work on the fastai IMDb example:\n",
    "# https://github.com/kgero/style-gen\n",
    "from fastai_old.text import *\n",
    "import html\n",
    "import spacy \n",
    "\n",
    "spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "These sections initialize the learners and and dictionary mappings nesseccary to generate lyrics from the trained models. This is similar to the initialization for training, but skips many steps which are either unneccessary for using the model or whose results have been saved and can simply be loaded back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These values are used in loading the models\n",
    "num_verses = 3\n",
    "verses = [0] * num_verses\n",
    "chorus = ''\n",
    "\n",
    "#This determines which of the three trained models the notebook will use to generate lyrics\n",
    "#The options are 'large_rap', 'small_rap', or 'small_country'\n",
    "model = 'large_rap' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('data/')\n",
    "LM_PATH=Path('data/model_lm/')\n",
    "LM_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27366, 6762)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if model = 'large_rap':\n",
    "    itosv = pickle.load(open(LM_PATH/'tmp'/'itos-verse-rap-verylarge.pkl', 'rb'))\n",
    "    itosc = pickle.load(open(LM_PATH/'tmp'/'itos-chorus-rap-verylarge.pkl', 'rb'))\n",
    "if model = 'small_rap':\n",
    "    itosv = pickle.load(open(LM_PATH/'tmp'/'itos-large-verse.pkl', 'rb'))\n",
    "    itosc = pickle.load(open(LM_PATH/'tmp'/'itos-large-chorus.pkl', 'rb'))\n",
    "if model = 'small_country':\n",
    "    itosv = pickle.load(open(LM_PATH/'tmp'/'itos-verse-country.pkl', 'rb'))\n",
    "    itosc = pickle.load(open(LM_PATH/'tmp'/'itos-chorus-country.pkl', 'rb'))\n",
    "\n",
    "stoiv = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itosv)})\n",
    "stoic = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itosc)})\n",
    "\n",
    "vsv=len(itosv)\n",
    "vsc=len(itosc)\n",
    "vsv, vsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these sets are kept empty since the model doesn't need to be trained\n",
    "trn_lm = np.empty([10,2])\n",
    "val_lm = np.empty([10,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: 0 70\n",
      "DATA: 0 70\n"
     ]
    }
   ],
   "source": [
    "#This bloack creates the models\n",
    "em_sz,nh,nl = 400,1150,3\n",
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7\n",
    "wd=1e-7\n",
    "bptt=70\n",
    "bs=52\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
    "mdv = LanguageModelData(PATH, 1, vsv, trn_dl, val_dl, bs=bs, bptt=bptt)\n",
    "mdc = LanguageModelData(PATH, 1, vsc, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT <fastai_old.text.LanguageModelData object at 0x7fdac8876470>\n",
      "INIT <fastai_old.text.LanguageModelData object at 0x7fdac88764e0>\n"
     ]
    }
   ],
   "source": [
    "# And finally creates the learners\n",
    "learnerv= mdv.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learnerc= mdc.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation Funcitons\n",
    "These are the two functions for generating lyrics from the models. These are nesseccary to take the predicitons from the model and turn them into a useable block of text. There is a separate function for verses and choruses as they have different styles which we are trying to replicate. The difference between these functions is better discussed in the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_verse(m, s, itos, stoi, l=20):\n",
    "    m[0].bs=1  # Set batch size to 1\n",
    "    m.eval()  # Turn off dropout\n",
    "    m.reset()  # Reset hidden state\n",
    "    m[0].bs=bs  # Put the batch size back to what it was\n",
    "\n",
    "    ss = s.lower().split()\n",
    "    si = [stoi[w] for w in ss]\n",
    "    t = torch.autograd.Variable(torch.cuda.LongTensor(np.array([si])))\n",
    "    \n",
    "    res,*_ = m(t)\n",
    "    \n",
    "    output = s + ' '\n",
    "    count = 0\n",
    "    while True:\n",
    "        n = torch.multinomial(res[-1].exp(), 10)  # drawing from probability distribution\n",
    "        n = n[1] if n.data[0]==0 else n[0]\n",
    "        if itos[int(n)] == '\\n' and count > l:\n",
    "            output += \"\\n\"\n",
    "            break\n",
    "        if not any (x in itos[int(n)] for x in ['xbos', 'xfld']):\n",
    "            output += itos[int(n)] + ' '\n",
    "        res,*_ = m(n.unsqueeze(0).unsqueeze(0))  # sometimes need an extra .unsqueeze(0)\n",
    "        count += 1\n",
    "    return output\n",
    "\n",
    "def generate_text_chorus(m, s, itos, stoi, l=20):\n",
    "    m[0].bs=1  # Set batch size to 1\n",
    "    m.eval()  # Turn off dropout\n",
    "    m.reset()  # Reset hidden state\n",
    "    m[0].bs=bs  # Put the batch size back to what it was\n",
    "\n",
    "    ss = s.lower().split()\n",
    "    si = [stoi[w] for w in ss]\n",
    "    t = torch.autograd.Variable(torch.cuda.LongTensor(np.array([si])))\n",
    "    \n",
    "    res,*_ = m(t)\n",
    "    \n",
    "    output = s + ' '\n",
    "    count = 0\n",
    "    while True:\n",
    "        p = np.random.choose([0,1], p=[0.1, 0.9])\n",
    "        if p ==1:\n",
    "            n = torch.multinomial(res[-1].exp(), 10)  # drawing from probability distribution\n",
    "        else:\n",
    "            n = res[-1].topk(5)[1]  # top word\n",
    "        n = n[1] if n.data[0]==0 else n[0]\n",
    "        if itos[int(n)] == '\\n' and count > l:\n",
    "            output += \"\\n\"\n",
    "            break\n",
    "        if not any (x in itos[int(n)] for x in ['xbos', 'xfld']):\n",
    "            output += itos[int(n)] + ' '\n",
    "        res,*_ = m(n.unsqueeze(0).unsqueeze(0))  # sometimes need an extra .unsqueeze(0)\n",
    "        count += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation\n",
    "Here is where the lyrics are actually generated. To make better use of the available time only verse and chorus models were trained, so a final implementation would be more robust and complete. This cell is set up to run any of the three models trained for the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == 'large_rap':\n",
    "    learnerv.load('lm_30epochs-verse-rap-verylarge')\n",
    "    learnerc.load('lm_30epochs-chorus-rap-verylarge')\n",
    "if model == 'small_rap':\n",
    "    learnerv.load('lm_30epochs-large-verse-set')\n",
    "    learnerc.load('lm_30epochs-large-chorus')\n",
    "if model == 'small_country':\n",
    "    learnerv.load('lm_30epochs-verse-country')\n",
    "    learnerc.load('lm_30epochs-chorus-country')\n",
    "\n",
    "#These strings are the seeds for the verses\n",
    "verse_strings = [\"this is the way I\", \"somedays the paint\", \"which way does the road\"]\n",
    "\n",
    "#This is the seed string for the chorus\n",
    "chorus_string = \"these days they ca n't\"\n",
    "\n",
    "mv=learnerv.model\n",
    "for i in range(num_verses):\n",
    "    verses[i] = generate_text_verse(mv, verse_strings[i], itosv, stoiv, l=150)\n",
    "\n",
    "mc=learnerc.model\n",
    "chorus = generate_text_verse(mc, chorus_string, itosc, stoic, l=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function un-does \n",
    "def clean_output(x):\n",
    "    return x.replace(\" n't\", \"n't\").replace(\" ' til\", \"@'til\").replace(\" ' cause\", \"@'cause\").replace(\n",
    "        \" '\", \"'\").replace(\"@'til\", \" 'til\").replace(\"@'cause\", \" 'cause\").replace(\" ,\", \",\").replace(\"1 \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Intro]\n",
      "\n",
      "[Verse 1]\n",
      "this is the way I â€™m makaveli, met a bad one patiently \n",
      " hit the bar with one mack, then send my nigga next to me, and go head \n",
      " so i abide, to remember the guys who was fly \n",
      " take a phone or two, to the crib i saw you for a moment \n",
      " put the balls to the lip, one time for the kilo \n",
      " pop a pill, hit the crib, now you on my snack elijah \n",
      " what's the fuck the soul of the killer ? \n",
      " since they don't hear me, i'm seekin' another midnight \n",
      " what's the problem girl ? don't plan 'til you get it \n",
      " rip your head off with the thinking of the sun \n",
      " plottin' on them friday night nights, we'll sleep late \n",
      " t.o.p, nobody knows if we were \n",
      "\n",
      "\n",
      "[Chorus]\n",
      "these days they can't change bringing somethin' hot to you \n",
      " the na - th - th - this is the rugged shit \n",
      " t_up aids is gold, t_up waiters is platinum \n",
      " sit down, ask them where you get your facts from \n",
      " five hundred thousand niggas in the hood with it \n",
      " and a million more niggas is gettin ready to get it \n",
      "  t_up krs is to live it up in the game \n",
      " your man be a sucker for love \n",
      " to let get all you can be \n",
      " rah yo i'm tryin to get savin me \n",
      "\n",
      "\n",
      "[Verse 2]\n",
      "somedays the paint eff with it cause i love it fuming \n",
      " i mean, damn, i spend my days in the studio \n",
      " prayin' for my increase, talkin' bout shit gon' be hard in the paint \n",
      " lookin' at the picture then i'm filling some crack \n",
      " ( you can see me now ) in every hood in the hood \n",
      " back know i got you feelin what i'm doin \n",
      " got it, guarantee you wants it \n",
      " understand it, i live it \n",
      " this is exotic shit, so you hatin on the dog shit \n",
      " get a six - pack, break me down dick - tune \n",
      " you chumps don't know, spit the venom, gorilla shit \n",
      " through the lyrical shit \n",
      " kick it in your dome, rip your fanatic skills \n",
      " stick you in your motherfucking wood \n",
      "\n",
      "\n",
      "[Chorus]\n",
      "these days they can't change bringing somethin' hot to you \n",
      " the na - th - th - this is the rugged shit \n",
      " t_up aids is gold, t_up waiters is platinum \n",
      " sit down, ask them where you get your facts from \n",
      " five hundred thousand niggas in the hood with it \n",
      " and a million more niggas is gettin ready to get it \n",
      "  t_up krs is to live it up in the game \n",
      " your man be a sucker for love \n",
      " to let get all you can be \n",
      " rah yo i'm tryin to get savin me \n",
      "\n",
      "\n",
      "[Verse 3]\n",
      "which way does the road kings of kings who died upon you bap \n",
      " in the pedophiles, bounce to the swoop, play the act \n",
      " stop wherever you are at where the food at, dawg \n",
      " cause you can get it too \n",
      " bullshittin don't stress that \n",
      " and i'm played like a retard \n",
      " if you stand besides me, now you're nervous as the cleavage \n",
      " come to give me the space and i'm wondering what it's gon na be \n",
      " you got ta bitch from the bottom of the blackberry shirt \n",
      " and even when a girl's candy still nc in her head \n",
      " it makes me wanna re - sneak \n",
      " if i meet her, i'm gon' leave her \n",
      " or throw me her panties that dress all white with the lipstick \n",
      " and if that don't work iâ€™mma need her to twist with leaves \n",
      "\n",
      "\n",
      "[Chorus]\n",
      "these days they can't change bringing somethin' hot to you \n",
      " the na - th - th - this is the rugged shit \n",
      " t_up aids is gold, t_up waiters is platinum \n",
      " sit down, ask them where you get your facts from \n",
      " five hundred thousand niggas in the hood with it \n",
      " and a million more niggas is gettin ready to get it \n",
      "  t_up krs is to live it up in the game \n",
      " your man be a sucker for love \n",
      " to let get all you can be \n",
      " rah yo i'm tryin to get savin me \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('[Intro]')\n",
    "for i in range(num_verses):\n",
    "    print('\\n[Verse ' + str(i + 1) + ']')\n",
    "    print(clean_output(verses[i]))\n",
    "    print('\\n[Chorus]')\n",
    "    print(clean_output(chorus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

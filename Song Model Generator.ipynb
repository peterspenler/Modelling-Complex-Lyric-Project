{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook was adapted from kgero's work on the fastai IMDb example:\n",
    "# https://github.com/kgero/style-gen\n",
    "from fastai_old.text import *\n",
    "import html\n",
    "import spacy \n",
    "\n",
    "spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "These sections initialize the learners and and dictionary mappings nesseccary to generate lyrics from the trained models. This is similar to the initialization for training, but skips many steps which are either unneccessary for using the model or whose results have been saved and can simply be loaded back\n",
    "\n",
    "Before using this model the 'models.tar.gz' file must be downloaded from:\n",
    "\n",
    "https://github.com/peterspenler/Modelling-Complex-Lyric-Project/releases/tag/v1.0\n",
    "\n",
    "and extracted into the data folder. This archive contains the pretrained model nessecarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These values are used in loading the models\n",
    "num_verses = 3\n",
    "verses = [0] * num_verses\n",
    "chorus = ''\n",
    "\n",
    "#This determines which of the three trained models the notebook will use to generate lyrics\n",
    "#The options are 'large_rap', 'small_rap', or 'small_country'\n",
    "model = 'small_rap' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('data/')\n",
    "LM_PATH=Path('data/model_lm/')\n",
    "LM_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == 'large_rap':\n",
    "    itosv = pickle.load(open(LM_PATH/'tmp'/'itos-verse-rap-verylarge.pkl', 'rb'))\n",
    "    itosc = pickle.load(open(LM_PATH/'tmp'/'itos-chorus-rap-verylarge.pkl', 'rb'))\n",
    "if model == 'small_rap':\n",
    "    itosv = pickle.load(open(LM_PATH/'tmp'/'itos-large-verse.pkl', 'rb'))\n",
    "    itosc = pickle.load(open(LM_PATH/'tmp'/'itos-large-chorus.pkl', 'rb'))\n",
    "if model == 'small_country':\n",
    "    itosv = pickle.load(open(LM_PATH/'tmp'/'itos-verse-country.pkl', 'rb'))\n",
    "    itosc = pickle.load(open(LM_PATH/'tmp'/'itos-chorus-country.pkl', 'rb'))\n",
    "\n",
    "stoiv = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itosv)})\n",
    "stoic = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itosc)})\n",
    "\n",
    "vsv=len(itosv)\n",
    "vsc=len(itosc)\n",
    "vsv, vsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these sets are kept empty since the model doesn't need to be trained\n",
    "trn_lm = np.empty([10,2])\n",
    "val_lm = np.empty([10,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This bloack creates the models\n",
    "em_sz,nh,nl = 400,1150,3\n",
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7\n",
    "wd=1e-7\n",
    "bptt=70\n",
    "bs=52\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
    "mdv = LanguageModelData(PATH, 1, vsv, trn_dl, val_dl, bs=bs, bptt=bptt)\n",
    "mdc = LanguageModelData(PATH, 1, vsc, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally creates the learners\n",
    "learnerv= mdv.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learnerc= mdc.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation Funcitons\n",
    "These are the two functions for generating lyrics from the models. These are nesseccary to take the predicitons from the model and turn them into a useable block of text. There is a separate function for verses and choruses as they have different styles which we are trying to replicate. The difference between these functions is better discussed in the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_verse(m, s, itos, stoi, l=20):\n",
    "    m[0].bs=1  # Set batch size to 1\n",
    "    m.eval()  # Turn off dropout\n",
    "    m.reset()  # Reset hidden state\n",
    "    m[0].bs=bs  # Put the batch size back to what it was\n",
    "\n",
    "    ss = s.lower().split()\n",
    "    si = [stoi[w] for w in ss]\n",
    "    t = torch.autograd.Variable(torch.cuda.LongTensor(np.array([si])))\n",
    "    \n",
    "    res,*_ = m(t)\n",
    "    \n",
    "    output = s + ' '\n",
    "    count = 0\n",
    "    while True:\n",
    "        n = torch.multinomial(res[-1].exp(), 10)  # drawing from probability distribution\n",
    "        n = n[1] if n.data[0]==0 else n[0]\n",
    "        if itos[int(n)] == '\\n' and count > l:\n",
    "            output += \"\\n\"\n",
    "            break\n",
    "        if not any (x in itos[int(n)] for x in ['xbos', 'xfld']):\n",
    "            output += itos[int(n)] + ' '\n",
    "        res,*_ = m(n.unsqueeze(0).unsqueeze(0))  # sometimes need an extra .unsqueeze(0)\n",
    "        count += 1\n",
    "    return output\n",
    "\n",
    "def generate_text_chorus(m, s, itos, stoi, l=20):\n",
    "    m[0].bs=1  # Set batch size to 1\n",
    "    m.eval()  # Turn off dropout\n",
    "    m.reset()  # Reset hidden state\n",
    "    m[0].bs=bs  # Put the batch size back to what it was\n",
    "\n",
    "    ss = s.lower().split()\n",
    "    si = [stoi[w] for w in ss]\n",
    "    t = torch.autograd.Variable(torch.cuda.LongTensor(np.array([si])))\n",
    "    \n",
    "    res,*_ = m(t)\n",
    "    \n",
    "    output = s + ' '\n",
    "    count = 0\n",
    "    while True:\n",
    "        p = np.random.choice([0,1], p=[0.1, 0.9])\n",
    "        if p ==1:\n",
    "            n = torch.multinomial(res[-1].exp(), 10)  # drawing from probability distribution\n",
    "        else:\n",
    "            n = res[-1].topk(5)[1]  # top word\n",
    "        n = n[1] if n.data[0]==0 else n[0]\n",
    "        if itos[int(n)] == '\\n' and count > l:\n",
    "            output += \"\\n\"\n",
    "            break\n",
    "        if not any (x in itos[int(n)] for x in ['xbos', 'xfld']):\n",
    "            output += itos[int(n)] + ' '\n",
    "        res,*_ = m(n.unsqueeze(0).unsqueeze(0))  # sometimes need an extra .unsqueeze(0)\n",
    "        count += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation\n",
    "Here is where the lyrics are actually generated. To make better use of the available time only verse and chorus models were trained, so a final implementation would be more robust and complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == 'large_rap':\n",
    "    learnerv.load('lm_30epochs-verse-rap-verylarge')\n",
    "    learnerc.load('lm_30epochs-chorus-rap-verylarge')\n",
    "if model == 'small_rap':\n",
    "    learnerv.load('lm_30epochs-large-verse-set')\n",
    "    learnerc.load('lm_30epochs-large-chorus')\n",
    "if model == 'small_country':\n",
    "    learnerv.load('lm_30epochs-verse-country')\n",
    "    learnerc.load('lm_30epochs-chorus-country')\n",
    "\n",
    "#These strings are the seeds for the verses\n",
    "verse_strings = [\"this is the way I\", \"somedays the paint\", \"which way does the road\"]\n",
    "\n",
    "#This is the seed string for the chorus\n",
    "chorus_string = \"these days they\"\n",
    "\n",
    "mv=learnerv.model\n",
    "for i in range(num_verses):\n",
    "    verses[i] = generate_text_verse(mv, verse_strings[i], itosv, stoiv, l=150)\n",
    "\n",
    "mc=learnerc.model\n",
    "chorus = generate_text_chorus(mc, chorus_string, itosc, stoic, l=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function un-does \n",
    "def clean_output(x):\n",
    "    return x.replace(\" n't\", \"n't\").replace(\" ' til\", \"@'til\").replace(\" ' cause\", \"@'cause\").replace(\n",
    "        \" '\", \"'\").replace(\"@'til\", \" 'til\").replace(\"@'cause\", \" 'cause\").replace(\" ,\", \",\").replace(\"1 \", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Results\n",
    "Finally this prints the results of the generation in a structured format that mimics the Genius.com format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[Intro]')\n",
    "for i in range(num_verses):\n",
    "    print('\\n[Verse ' + str(i + 1) + ']')\n",
    "    print(clean_output(verses[i]))\n",
    "    print('\\n[Chorus]')\n",
    "    print(clean_output(chorus))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7f728062ecc0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai_old.text import *\n",
    "import html\n",
    "import spacy \n",
    "\n",
    "spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_verses = 3\n",
    "verses = [0] * num_verses\n",
    "chorus = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('data/')\n",
    "LM_PATH=Path('data/model_lm/')\n",
    "LM_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5210, 2215)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment these two lines for the smaller hip hop model\n",
    "#itosv = pickle.load(open(LM_PATH/'tmp'/'itos-large-verse.pkl', 'rb'))\n",
    "#itosc = pickle.load(open(LM_PATH/'tmp'/'itos-large-chorus.pkl', 'rb'))\n",
    "# Uncomment these two lines for the smaller country model\n",
    "itosv = pickle.load(open(LM_PATH/'tmp'/'itos-verse-country.pkl', 'rb'))\n",
    "itosc = pickle.load(open(LM_PATH/'tmp'/'itos-chorus-country.pkl', 'rb'))\n",
    "# Uncomment these two lines for the larger hip hop model\n",
    "#itosv = pickle.load(open(LM_PATH/'tmp'/'itos-large-verse.pkl', 'rb'))\n",
    "#itosc = pickle.load(open(LM_PATH/'tmp'/'itos-large-chorus.pkl', 'rb'))\n",
    "\n",
    "\n",
    "stoiv = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itosv)})\n",
    "stoic = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itosc)})\n",
    "\n",
    "vsv=len(itosv)\n",
    "vsc=len(itosc)\n",
    "vsv, vsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.empty([10,2])\n",
    "val_lm = np.empty([10,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: 0 70\n",
      "DATA: 0 70\n"
     ]
    }
   ],
   "source": [
    "em_sz,nh,nl = 400,1150,3\n",
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7\n",
    "wd=1e-7\n",
    "bptt=70\n",
    "bs=52\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
    "mdv = LanguageModelData(PATH, 1, vsv, trn_dl, val_dl, bs=bs, bptt=bptt)\n",
    "mdc = LanguageModelData(PATH, 1, vsc, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT <fastai_old.text.LanguageModelData object at 0x7f7201c28ac8>\n",
      "INIT <fastai_old.text.LanguageModelData object at 0x7f7201c28b38>\n"
     ]
    }
   ],
   "source": [
    "learnerv= mdv.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learnerc= mdc.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "#learner.model.load_state_dict(wgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_verse(m, s, itos, stoi, l=20):\n",
    "    m[0].bs=1  # Set batch size to 1\n",
    "    m.eval()  # Turn off dropout\n",
    "    m.reset()  # Reset hidden state\n",
    "    m[0].bs=bs  # Put the batch size back to what it was\n",
    "\n",
    "    ss = s.lower().split()\n",
    "    si = [stoi[w] for w in ss]\n",
    "    t = torch.autograd.Variable(torch.cuda.LongTensor(np.array([si])))\n",
    "    \n",
    "    res,*_ = m(t)\n",
    "    \n",
    "    output = s + ' '\n",
    "    count = 0\n",
    "    while True:\n",
    "        #n = res[-1].topk(5)[1]  # top word\n",
    "        n = torch.multinomial(res[-1].exp(), 10)  # drawing from probability distribution\n",
    "        n = n[1] if n.data[0]==0 else n[0]\n",
    "        if itos[int(n)] == '\\n' and count > l:\n",
    "            output += \"\\n\"\n",
    "            break\n",
    "        if not any (x in itos[int(n)] for x in ['xbos', 'xfld']):\n",
    "            output += itos[int(n)] + ' '\n",
    "        res,*_ = m(n.unsqueeze(0).unsqueeze(0))  # sometimes need an extra .unsqueeze(0)\n",
    "        count += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SequentialRNN:\n\tsize mismatch for 0.encoder.weight: copying a param with shape torch.Size([17190, 400]) from checkpoint, the shape in current model is torch.Size([5210, 400]).\n\tsize mismatch for 0.encoder_with_dropout.embed.weight: copying a param with shape torch.Size([17190, 400]) from checkpoint, the shape in current model is torch.Size([5210, 400]).\n\tsize mismatch for 1.decoder.weight: copying a param with shape torch.Size([17190, 400]) from checkpoint, the shape in current model is torch.Size([5210, 400]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b44be03b51ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Uncomment these two lines for the smaller hip hop model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearnerv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lm_30epochs-large-verse-set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlearnerc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lm_30epochs-large-chorus'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Uncomment these two lines for the smaller country model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#learnerv.load('lm_30epochs-verse-country')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Project/current_VCS/fastai_old/learner.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'swa_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-swa.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Project/current_VCS/fastai_old/torch_imports.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(m, p)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_raw'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_raw'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 769\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_named_members\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_members_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SequentialRNN:\n\tsize mismatch for 0.encoder.weight: copying a param with shape torch.Size([17190, 400]) from checkpoint, the shape in current model is torch.Size([5210, 400]).\n\tsize mismatch for 0.encoder_with_dropout.embed.weight: copying a param with shape torch.Size([17190, 400]) from checkpoint, the shape in current model is torch.Size([5210, 400]).\n\tsize mismatch for 1.decoder.weight: copying a param with shape torch.Size([17190, 400]) from checkpoint, the shape in current model is torch.Size([5210, 400])."
     ]
    }
   ],
   "source": [
    "#Uncomment these two lines for the smaller hip hop model\n",
    "learnerv.load('lm_30epochs-large-verse-set')\n",
    "learnerc.load('lm_30epochs-large-chorus')\n",
    "#Uncomment these two lines for the smaller country model\n",
    "#learnerv.load('lm_30epochs-verse-country')\n",
    "#learnerc.load('lm_30epochs-chorus-country')\n",
    "#Uncomment these two lines for the larger hip hop model\n",
    "#learnerv.load('lm_30epochs-verse-rap-verylarge')\n",
    "#learnerc.load('lm_30epochs-chorus-rap-verylarge')\n",
    "\n",
    "#These strings are the seeds for the verses\n",
    "verse_strings = [\"this is the way I\", \"somedays the paint\", \"which way does the road\"]\n",
    "\n",
    "#This is the seed string for the chorus\n",
    "chorus_string = \"these days they ca n't\"\n",
    "\n",
    "mv=learnerv.model\n",
    "for i in range(num_verses):\n",
    "    verses[i] = generate_text_verse(mv, verse_strings[i], itosv, stoiv, l=150)\n",
    "\n",
    "mc=learnerc.model\n",
    "chorus = generate_text_verse(mc, chorus_string, itosc, stoic, l=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_output(x):\n",
    "    return x.replace(\" n't\", \"n't\").replace(\" ' til\", \"@'til\").replace(\" ' cause\", \"@'cause\").replace(\n",
    "        \" '\", \"'\").replace(\"@'til\", \" 'til\").replace(\"@'cause\", \" 'cause\").replace(\" ,\", \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[Intro]')\n",
    "for i in range(num_verses):\n",
    "    print('\\n[Verse ' + str(i + 1) + ']')\n",
    "    print(clean_output(verses[i]))\n",
    "    print('\\n[Chorus]')\n",
    "    print(clean_output(chorus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
